{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9af4c962",
   "metadata": {},
   "source": [
    "# Lesson 3: Financial Risk Assessment Prompt Optimization\n",
    "\n",
    "## Systematic Refinement for Financial AI Accuracy\n",
    "\n",
    "In this hands-on exercise, you will learn to systematically refine and optimize prompts for a financial risk assessment system. You'll implement automated testing frameworks, measure prompt performance, and iteratively improve accuracy for critical financial decision-making scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b03c6d8",
   "metadata": {},
   "source": [
    "## Outline:\n",
    "\n",
    "- **Baseline Risk Assessment**: Initial prompt for customer risk evaluation\n",
    "- **Systematic Refinement Framework**: Automated testing and measurement systems\n",
    "- **Optimization Techniques**: Best practices for instruction clarity and compliance\n",
    "- **Advanced Refinement**: Context optimization and parameter tuning\n",
    "- **Performance Evaluation**: Quantitative comparison of prompt variations\n",
    "- **Production Validation**: Testing with complex real-world scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff1ba10",
   "metadata": {},
   "source": [
    "## Setup Instructions\n",
    "\n",
    "Before starting this exercise:\n",
    "\n",
    "1. **Install Required Packages**: Run `pip install -r ../../requirements.txt` in your terminal\n",
    "2. **Configure API Key**: \n",
    "   - Open the `.env` file in the root directory\n",
    "   - Replace `your_openai_api_key_here` with your actual OpenAI API key\n",
    "   - Save the file\n",
    "3. **Verify Setup**: Run the import and setup cells below to ensure everything works\n",
    "\n",
    "**Note**: The notebook automatically loads your API key from the `.env` file in the root directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5d9c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "import json\n",
    "import time\n",
    "import statistics\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "# Load environment variables from the root .env file\n",
    "load_dotenv('../../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee1f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup OpenAI client\n",
    "client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")  # Load from .env file\n",
    ")\n",
    "\n",
    "def get_completion(system_prompt, user_prompt, model=\"gpt-4o-mini\", temperature=0.3):\n",
    "    \"\"\"\n",
    "    Function to get a completion from the OpenAI API.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f375d9",
   "metadata": {},
   "source": [
    "## Financial Risk Assessment Scenarios\n",
    "\n",
    "We'll use these customer scenarios to test and optimize our risk assessment prompts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559f7801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test scenarios for prompt optimization\n",
    "test_scenarios = {\n",
    "    \"low_risk\": {\n",
    "        \"scenario\": \"\"\"\n",
    "Customer Profile: Local Retail Store\n",
    "- Business Type: Family-owned grocery store\n",
    "- Account Age: 8 years\n",
    "- Monthly Revenue: $45,000\n",
    "- Transaction Pattern: Daily deposits $1,200-2,000, consistent timing\n",
    "- Geographic Scope: Single location, local suppliers\n",
    "- Documentation: Complete business licenses, tax returns current\n",
    "- Owner Background: Clean credit history, local community member\n",
    "- Banking History: No previous compliance issues\n",
    "\"\"\",\n",
    "        \"expected_risk\": \"Low\"\n",
    "    },\n",
    "    \"medium_risk\": {\n",
    "        \"scenario\": \"\"\"\n",
    "Customer Profile: Import/Export Business\n",
    "- Business Type: International trade company\n",
    "- Account Age: 2.5 years\n",
    "- Monthly Revenue: $800,000\n",
    "- Transaction Pattern: Large wire transfers ($50K-200K), irregular timing\n",
    "- Geographic Scope: Asia-Pacific region, multiple countries\n",
    "- Documentation: Some supplier documentation missing\n",
    "- Owner Background: Limited credit history, recent immigrant\n",
    "- Banking History: Minor documentation delays, no violations\n",
    "\"\"\",\n",
    "        \"expected_risk\": \"Medium\"\n",
    "    },\n",
    "    \"high_risk\": {\n",
    "        \"scenario\": \"\"\"\n",
    "Customer Profile: Consulting Services LLC\n",
    "- Business Type: Financial consulting\n",
    "- Account Age: 6 months\n",
    "- Monthly Revenue: $2.3M\n",
    "- Transaction Pattern: Immediate large transfers after deposits\n",
    "- Geographic Scope: Offshore jurisdictions (Cayman, Malta)\n",
    "- Documentation: Minimal business documentation\n",
    "- Owner Background: Multiple previous business dissolutions\n",
    "- Banking History: Previous account closures at other banks\n",
    "\"\"\",\n",
    "        \"expected_risk\": \"High\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Test scenarios loaded for prompt optimization...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed40385e",
   "metadata": {},
   "source": [
    "## 1. Baseline Risk Assessment (3 min)\n",
    "\n",
    "First, let's create a basic prompt and establish baseline performance for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed3d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill in the missing parts marked with ++++++++++++\n",
    "# Your Task: Create a basic risk assessment prompt\n",
    "# For example: baseline_prompt = \"You are a bank risk analyst. Assess the customer risk level as Low, Medium, or High.\"\n",
    "baseline_prompt = \"++++++++++++++\"\n",
    "\n",
    "def test_prompt_baseline(prompt, scenarios):\n",
    "    \"\"\"Test a prompt against all scenarios and return results\"\"\"\n",
    "    results = {}\n",
    "    for risk_level, data in scenarios.items():\n",
    "        response = get_completion(prompt, data[\"scenario\"])\n",
    "        results[risk_level] = {\n",
    "            \"response\": response,\n",
    "            \"expected\": data[\"expected_risk\"]\n",
    "        }\n",
    "    return results\n",
    "\n",
    "# Test baseline prompt\n",
    "print(\"=== BASELINE PROMPT PERFORMANCE ===\")\n",
    "baseline_results = test_prompt_baseline(baseline_prompt, test_scenarios)\n",
    "\n",
    "for risk_level, result in baseline_results.items():\n",
    "    print(f\"\\n{risk_level.upper()} RISK SCENARIO:\")\n",
    "    print(f\"Expected: {result['expected']}\")\n",
    "    print(f\"Response: {result['response'][:200]}...\")  # Truncated for display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4944c851",
   "metadata": {},
   "source": [
    "## 2. Systematic Refinement Framework (5 min)\n",
    "\n",
    "Now let's build an automated testing framework to systematically improve our prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2ba549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill in the missing prompt variations marked with ++++++++++++\n",
    "# Your Task: Create prompt variations to test different approaches\n",
    "prompt_variations = {\n",
    "    \"baseline\": baseline_prompt,\n",
    "    \n",
    "    \"structured_output\": \"\"\"++++++++++++++\n",
    "(Create a prompt that requests structured output with specific format)\n",
    "Example: You are a bank risk analyst. Assess customer risk and respond with:\n",
    "Risk Level: [Low/Medium/High]\n",
    "Key Factors: [List main risk factors]\n",
    "Confidence: [High/Medium/Low]\n",
    "\"\"\",\n",
    "    \n",
    "    \"detailed_criteria\": \"\"\"++++++++++++++\n",
    "(Create a prompt with specific risk assessment criteria)\n",
    "Example: You are a bank risk analyst. Evaluate customers using these criteria:\n",
    "- Account age and history\n",
    "- Transaction patterns and volumes\n",
    "- Geographic risk factors\n",
    "- Documentation completeness\n",
    "Assign risk level: Low, Medium, or High\n",
    "\"\"\",\n",
    "    \n",
    "    \"compliance_focused\": \"\"\"++++++++++++++\n",
    "(Create a prompt emphasizing regulatory compliance)\n",
    "Example: You are a compliance officer conducting customer due diligence.\n",
    "Apply BSA/AML guidelines to assess risk level based on:\n",
    "- Customer profile and background\n",
    "- Transaction monitoring findings\n",
    "- Geographic and jurisdictional factors\n",
    "Classify as: Low Risk, Medium Risk, or High Risk\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "print(\"Prompt variations created for testing...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b949e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated testing framework\n",
    "def evaluate_prompt_accuracy(results, scenarios):\n",
    "    \"\"\"Evaluate how well prompt results match expected risk levels\"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for risk_level, result in results.items():\n",
    "        expected = result['expected']\n",
    "        response = result['response'].upper()\n",
    "        \n",
    "        # Simple matching - check if expected risk level appears in response\n",
    "        if expected.upper() in response:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    \n",
    "    return correct / total if total > 0 else 0\n",
    "\n",
    "def test_all_variations(variations, scenarios):\n",
    "    \"\"\"Test all prompt variations and calculate performance metrics\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for variation_name, prompt in variations.items():\n",
    "        print(f\"\\nTesting: {variation_name}\")\n",
    "        variation_results = test_prompt_baseline(prompt, scenarios)\n",
    "        accuracy = evaluate_prompt_accuracy(variation_results, scenarios)\n",
    "        \n",
    "        results[variation_name] = {\n",
    "            \"prompt\": prompt,\n",
    "            \"results\": variation_results,\n",
    "            \"accuracy\": accuracy\n",
    "        }\n",
    "        \n",
    "        print(f\"Accuracy: {accuracy:.2%}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# TODO: Run the automated testing (uncomment when prompts are filled in)\n",
    "# print(\"=== AUTOMATED PROMPT TESTING ===\")\n",
    "# all_results = test_all_variations(prompt_variations, test_scenarios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0aa9dd",
   "metadata": {},
   "source": [
    "## 3. Optimization Techniques (4 min)\n",
    "\n",
    "Let's apply specific optimization techniques to improve prompt performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2020a16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fill in the optimized prompt marked with ++++++++++++\n",
    "# Your Task: Create an optimized prompt combining the best techniques from your testing\n",
    "optimized_prompt = \"\"\"++++++++++++++\n",
    "(Create your best prompt incorporating lessons from variation testing)\n",
    "\n",
    "Consider including:\n",
    "- Clear role definition\n",
    "- Specific assessment criteria\n",
    "- Structured output format\n",
    "- Compliance considerations\n",
    "- Examples or guidelines\n",
    "\n",
    "Example structure:\n",
    "You are a [specific role] with expertise in [domain].\n",
    "Evaluate the customer using these criteria:\n",
    "[List specific criteria]\n",
    "Provide your assessment in this format:\n",
    "[Specific output structure]\n",
    "\"\"\"\n",
    "\n",
    "# Test optimization techniques\n",
    "optimization_tests = {\n",
    "    \"instruction_clarity\": {\n",
    "        \"prompt\": optimized_prompt,\n",
    "        \"temperature\": 0.1  # Lower temperature for consistency\n",
    "    },\n",
    "    \"context_optimization\": {\n",
    "        \"prompt\": optimized_prompt + \"\\n\\nFocus on regulatory compliance and risk mitigation.\",\n",
    "        \"temperature\": 0.3\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Optimization techniques prepared for testing...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fce2812",
   "metadata": {},
   "source": [
    "## 4. Advanced Refinement (3 min)\n",
    "\n",
    "Let's test advanced refinement techniques including parameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e60cdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test different temperature settings\n",
    "# Your Task: Test how temperature affects response consistency\n",
    "def test_temperature_consistency(prompt, scenario, temperatures=[0.1, 0.3, 0.7]):\n",
    "    \"\"\"Test how different temperatures affect response consistency\"\"\"\n",
    "    consistency_results = {}\n",
    "    \n",
    "    for temp in temperatures:\n",
    "        responses = []\n",
    "        # Run same prompt multiple times with different temperature\n",
    "        for _ in range(3):  # Test 3 times for consistency\n",
    "            response = get_completion(prompt, scenario, temperature=temp)\n",
    "            responses.append(response)\n",
    "        \n",
    "        consistency_results[temp] = responses\n",
    "    \n",
    "    return consistency_results\n",
    "\n",
    "# TODO: Test your optimized prompt with different temperatures\n",
    "print(\"=== TEMPERATURE CONSISTENCY TEST ===\")\n",
    "# Uncomment when optimized_prompt is ready:\n",
    "# temp_results = test_temperature_consistency(\n",
    "#     optimized_prompt, \n",
    "#     test_scenarios[\"medium_risk\"][\"scenario\"]\n",
    "# )\n",
    "# \n",
    "# for temp, responses in temp_results.items():\n",
    "#     print(f\"\\nTemperature {temp}:\")\n",
    "#     for i, response in enumerate(responses, 1):\n",
    "#         print(f\"Run {i}: {response[:100]}...\")  # Truncated for display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682537aa",
   "metadata": {},
   "source": [
    "## 5. Performance Evaluation (3 min)\n",
    "\n",
    "Let's compare all our prompt variations and select the best performing approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a0694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a comprehensive evaluation framework\n",
    "# Your Task: Implement evaluation metrics beyond simple accuracy\n",
    "\n",
    "def comprehensive_evaluation(prompt, scenarios):\n",
    "    \"\"\"Comprehensive evaluation including accuracy, consistency, and quality\"\"\"\n",
    "    results = test_prompt_baseline(prompt, scenarios)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = evaluate_prompt_accuracy(results, scenarios)\n",
    "    \n",
    "    # TODO: Add more evaluation metrics\n",
    "    # Calculate response length consistency\n",
    "    response_lengths = [len(result['response']) for result in results.values()]\n",
    "    length_consistency = 1 - (statistics.stdev(response_lengths) / statistics.mean(response_lengths)) if len(response_lengths) > 1 else 1\n",
    "    \n",
    "    # Calculate structured response adherence (simple check)\n",
    "    structured_responses = sum(1 for result in results.values() if 'Risk Level:' in result['response'] or 'Risk:' in result['response'])\n",
    "    structure_adherence = structured_responses / len(results)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"length_consistency\": length_consistency,\n",
    "        \"structure_adherence\": structure_adherence,\n",
    "        \"overall_score\": (accuracy + length_consistency + structure_adherence) / 3\n",
    "    }\n",
    "\n",
    "# TODO: Compare your best prompts\n",
    "print(\"=== COMPREHENSIVE EVALUATION ===\")\n",
    "# Uncomment when prompts are ready:\n",
    "# final_comparison = {\n",
    "#     \"baseline\": comprehensive_evaluation(baseline_prompt, test_scenarios),\n",
    "#     \"optimized\": comprehensive_evaluation(optimized_prompt, test_scenarios)\n",
    "# }\n",
    "# \n",
    "# for prompt_name, metrics in final_comparison.items():\n",
    "#     print(f\"\\n{prompt_name.upper()} PROMPT:\")\n",
    "#     print(f\"Accuracy: {metrics['accuracy']:.2%}\")\n",
    "#     print(f\"Length Consistency: {metrics['length_consistency']:.2%}\")\n",
    "#     print(f\"Structure Adherence: {metrics['structure_adherence']:.2%}\")\n",
    "#     print(f\"Overall Score: {metrics['overall_score']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32e4453",
   "metadata": {},
   "source": [
    "## 6. Production Validation (2 min)\n",
    "\n",
    "Test your refined prompts with complex, realistic scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc7ad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a complex validation scenario\n",
    "# Your Task: Design a challenging real-world scenario to test your optimized prompt\n",
    "production_scenario = \"\"\"++++++++++++++\n",
    "(Create a complex, realistic customer scenario that combines multiple risk factors)\n",
    "\n",
    "Example elements to include:\n",
    "- Mixed risk signals (some concerning, some legitimate)\n",
    "- Multiple business entities or relationships\n",
    "- Complex transaction patterns\n",
    "- Regulatory edge cases\n",
    "- Documentation and compliance challenges\n",
    "\n",
    "Customer Profile: [Your complex scenario]\n",
    "- Business Type: ++++++++++++++\n",
    "- Account Details: ++++++++++++++\n",
    "- Transaction Patterns: ++++++++++++++\n",
    "- Risk Factors: ++++++++++++++\n",
    "- Mitigating Factors: ++++++++++++++\n",
    "\"\"\"\n",
    "\n",
    "# TODO: Test your optimized prompt with the production scenario\n",
    "print(\"=== PRODUCTION VALIDATION ===\")\n",
    "# Uncomment when scenario and optimized_prompt are ready:\n",
    "# production_result = get_completion(optimized_prompt, production_scenario)\n",
    "# print(\"Complex Scenario Assessment:\")\n",
    "# print(production_result)\n",
    "print(\"Create your production scenario above, then uncomment the test code.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efb1d9a",
   "metadata": {},
   "source": [
    "## 7. Reflection & Optimization Analysis\n",
    "\n",
    "Analyze your optimization process and document key learnings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f480139",
   "metadata": {},
   "source": [
    "### Which optimization techniques were most effective for financial risk assessment?\n",
    "\n",
    "**TODO: Add your analysis below where you see ++++++++++++**\n",
    "\n",
    "**Prompt Structure Improvements:**\n",
    "- Most effective structural changes: ++++++++++++\n",
    "- Impact on accuracy: ++++++++++++\n",
    "- Impact on consistency: ++++++++++++\n",
    "\n",
    "**Instruction Clarity:**\n",
    "- Key refinements that improved clarity: ++++++++++++\n",
    "- Effect on response quality: ++++++++++++\n",
    "- Compliance alignment improvements: ++++++++++++\n",
    "\n",
    "**Parameter Optimization:**\n",
    "- Optimal temperature setting: ++++++++++++\n",
    "- Trade-offs between creativity and consistency: ++++++++++++\n",
    "- Model selection considerations: ++++++++++++\n",
    "\n",
    "**Performance Metrics:**\n",
    "- Accuracy improvement (baseline vs optimized): ++++++++++++\n",
    "- Most valuable evaluation metric: ++++++++++++\n",
    "- Areas requiring further refinement: ++++++++++++\n",
    "\n",
    "**Financial Services Applications:**\n",
    "- Key regulatory considerations: ++++++++++++\n",
    "- Risk mitigation through prompt design: ++++++++++++\n",
    "- Recommendations for production deployment: ++++++++++++\n",
    "\n",
    "**Optimization Process Insights:**\n",
    "- Most valuable refinement methodology: ++++++++++++\n",
    "- Challenges in automated evaluation: ++++++++++++\n",
    "- Recommendations for continuous improvement: ++++++++++++"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5ba5a8",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this exercise, we implemented systematic prompt refinement for financial risk assessment:\n",
    "\n",
    "1. **Baseline Assessment**: Established initial prompt performance benchmarks\n",
    "2. **Systematic Framework**: Built automated testing and evaluation systems\n",
    "3. **Optimization Techniques**: Applied prompt engineering best practices\n",
    "4. **Advanced Refinement**: Tested parameter optimization and consistency\n",
    "5. **Performance Evaluation**: Implemented comprehensive quality metrics\n",
    "6. **Production Validation**: Tested with complex, realistic scenarios\n",
    "\n",
    "Key insights for financial AI prompt optimization:\n",
    "- **Systematic Testing**: Automated frameworks enable objective comparison\n",
    "- **Multiple Metrics**: Accuracy alone isn't sufficient for financial applications\n",
    "- **Regulatory Alignment**: Compliance considerations must be built into prompts\n",
    "- **Iterative Improvement**: Continuous refinement delivers measurable gains\n",
    "- **Production Validation**: Real-world scenarios reveal optimization opportunities\n",
    "\n",
    "These optimization techniques provide a robust foundation for building reliable, compliant, and accurate financial AI systems! ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
