{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62a410b0",
   "metadata": {},
   "source": [
    "# Lesson 5: LLM Feedback Loops for Financial AI - Demo\n",
    "\n",
    "## Self-Improving Credit Assessment Systems\n",
    "\n",
    "This demonstration shows how to build LLM feedback loops where one AI system generates credit risk assessments, and another AI system evaluates and provides feedback to continuously improve the analysis quality. This represents iterative AI-to-AI learning for enhanced financial decision-making.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand LLM-to-LLM feedback loop architecture\n",
    "- Learn iterative improvement methodologies for financial AI\n",
    "- Master evaluation criteria design for AI system improvement\n",
    "- Observe quality enhancement through feedback integration\n",
    "- Practice building self-learning financial analysis systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35e8280",
   "metadata": {},
   "source": [
    "## What We'll Demonstrate:\n",
    "\n",
    "1. **Single-Pass Limitation**: Why one-time analysis isn't sufficient for complex decisions\n",
    "2. **Two-LLM Architecture**: Analyst LLM + Evaluator LLM working together\n",
    "3. **Feedback Integration**: How evaluation insights improve subsequent analysis\n",
    "4. **Iterative Improvement**: Multiple rounds of analysis → evaluation → refinement\n",
    "5. **Quality Metrics**: Measuring improvement across feedback iterations\n",
    "6. **Production Implementation**: Building self-learning financial AI systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46460438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Optional\n",
    "from dataclasses import dataclass, field\n",
    "import re\n",
    "\n",
    "# Load environment variables from the root .env file\n",
    "load_dotenv('../../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ac017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup OpenAI client for Vocareum environment\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openai.vocareum.com/v1\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")\n",
    "\n",
    "def get_completion(system_prompt, user_prompt, model=\"gpt-4o-mini\", temperature=0.3):\n",
    "    \"\"\"\n",
    "    Function to get a completion from the OpenAI API.\n",
    "    Args:\n",
    "        system_prompt: The system prompt defining the AI's role\n",
    "        user_prompt: The user's input or scenario  \n",
    "        model: The model to use (default is gpt-4o-mini)\n",
    "        temperature: Creativity level (lower = more consistent)\n",
    "    Returns:\n",
    "        completion text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt},\n",
    "            ],\n",
    "            temperature=temperature,\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dc73b2",
   "metadata": {},
   "source": [
    "## Credit Assessment Scenario\n",
    "\n",
    "For this demonstration, we'll use a credit risk assessment scenario where an AI system analyzes loan applications and improves through feedback loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a92838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data structures for credit assessment feedback loops\n",
    "\n",
    "@dataclass\n",
    "class CreditApplication:\n",
    "    \"\"\"Credit application data structure\"\"\"\n",
    "    applicant_name: str\n",
    "    annual_income: float\n",
    "    employment_years: int\n",
    "    credit_score: int\n",
    "    existing_debt: float\n",
    "    loan_amount: float\n",
    "    loan_purpose: str\n",
    "    collateral_value: float\n",
    "    debt_to_income_ratio: float\n",
    "\n",
    "@dataclass\n",
    "class CreditAssessment:\n",
    "    \"\"\"Credit assessment report structure\"\"\"\n",
    "    applicant_name: str\n",
    "    assessment_text: str\n",
    "    recommendation: str  # Approve, Conditional, Decline\n",
    "    risk_score: float  # 1-10 scale\n",
    "    interest_rate: float\n",
    "    key_factors: List[str]\n",
    "    risk_mitigation: List[str]\n",
    "    confidence_level: float\n",
    "    timestamp: str\n",
    "\n",
    "@dataclass \n",
    "class EvaluationFeedback:\n",
    "    \"\"\"Feedback from evaluator AI\"\"\"\n",
    "    overall_score: float  # 1-10\n",
    "    strengths: List[str]\n",
    "    weaknesses: List[str]\n",
    "    improvement_suggestions: List[str]\n",
    "    missing_analysis: List[str]\n",
    "    criteria_scores: Dict[str, float]\n",
    "\n",
    "# Sample credit application for testing\n",
    "sample_application = CreditApplication(\n",
    "    applicant_name=\"Sarah Martinez\",\n",
    "    annual_income=85000.0,\n",
    "    employment_years=3,\n",
    "    credit_score=720,\n",
    "    existing_debt=15000.0,\n",
    "    loan_amount=45000.0,\n",
    "    loan_purpose=\"Home improvement\",\n",
    "    collateral_value=25000.0,\n",
    "    debt_to_income_ratio=0.18\n",
    ")\n",
    "\n",
    "print(\"📋 Credit assessment scenario loaded for feedback loop demonstration\")\n",
    "print(\"Focus: Iterative AI improvement through LLM feedback\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580e1457",
   "metadata": {},
   "source": [
    "## Problem: Single-Pass Analysis Limitations\n",
    "\n",
    "First, let's see what happens with a single AI analysis without feedback loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8961279",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicCreditAnalyst:\n",
    "    \"\"\"Basic credit analyst without feedback capabilities\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.system_prompt = \"\"\"You are a credit analyst. Analyze loan applications and provide recommendations.\n",
    "        \n",
    "        Provide assessment including recommendation, risk factors, and interest rate.\"\"\"\n",
    "    \n",
    "    def analyze(self, application: CreditApplication) -> str:\n",
    "        \"\"\"Generate basic credit assessment\"\"\"\n",
    "        \n",
    "        app_text = f\"\"\"\n",
    "        Credit Application Analysis:\n",
    "        \n",
    "        Applicant: {application.applicant_name}\n",
    "        Annual Income: ${application.annual_income:,.2f}\n",
    "        Employment: {application.employment_years} years\n",
    "        Credit Score: {application.credit_score}\n",
    "        Existing Debt: ${application.existing_debt:,.2f}\n",
    "        Loan Request: ${application.loan_amount:,.2f} for {application.loan_purpose}\n",
    "        Collateral: ${application.collateral_value:,.2f}\n",
    "        Debt-to-Income: {application.debt_to_income_ratio:.1%}\n",
    "        \"\"\"\n",
    "        \n",
    "        return get_completion(self.system_prompt, app_text)\n",
    "\n",
    "# Test basic analysis\n",
    "basic_analyst = BasicCreditAnalyst()\n",
    "basic_result = basic_analyst.analyze(sample_application)\n",
    "\n",
    "print(\"=== BASIC SINGLE-PASS ANALYSIS ===\")\n",
    "print(basic_result)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"❌ PROBLEMS WITH SINGLE-PASS ANALYSIS:\")\n",
    "print(\"- No quality verification or validation\")\n",
    "print(\"- Inconsistent analysis depth and structure\") \n",
    "print(\"- No mechanism for improvement or learning\")\n",
    "print(\"- Potential gaps in risk assessment coverage\")\n",
    "print(\"- No feedback integration for quality enhancement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f4ba2a",
   "metadata": {},
   "source": [
    "## Solution: LLM Feedback Loop Architecture\n",
    "\n",
    "Now let's implement a two-LLM system where one analyzes and another evaluates for continuous improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6051d492",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreditAnalyst:\n",
    "    \"\"\"Advanced credit analyst with feedback integration\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.feedback_history = []\n",
    "        self.improvement_context = \"\"\n",
    "        \n",
    "    def generate_assessment(self, application: CreditApplication, iteration=1) -> CreditAssessment:\n",
    "        \"\"\"Generate credit assessment with feedback integration\"\"\"\n",
    "        \n",
    "        system_prompt = f\"\"\"You are a senior credit analyst with 10+ years of experience in loan underwriting.\n",
    "        \n",
    "        ANALYSIS REQUIREMENTS:\n",
    "        1. Comprehensive risk assessment using standard credit metrics\n",
    "        2. Clear recommendation (Approve/Conditional/Decline) with reasoning\n",
    "        3. Appropriate interest rate based on risk profile\n",
    "        4. Identification of key risk and mitigation factors\n",
    "        5. Confidence level in assessment (1-10 scale)\n",
    "        \n",
    "        {self.improvement_context}\n",
    "        \n",
    "        Structure your response clearly with specific sections for each requirement.\"\"\"\n",
    "        \n",
    "        application_prompt = f\"\"\"\n",
    "        CREDIT APPLICATION REVIEW - Iteration {iteration}\n",
    "        \n",
    "        Applicant Profile:\n",
    "        - Name: {application.applicant_name}\n",
    "        - Annual Income: ${application.annual_income:,.2f}\n",
    "        - Employment History: {application.employment_years} years current position\n",
    "        - Credit Score: {application.credit_score}\n",
    "        - Current Debt Load: ${application.existing_debt:,.2f}\n",
    "        \n",
    "        Loan Request:\n",
    "        - Amount: ${application.loan_amount:,.2f}\n",
    "        - Purpose: {application.loan_purpose}\n",
    "        - Available Collateral: ${application.collateral_value:,.2f}\n",
    "        - Debt-to-Income Ratio: {application.debt_to_income_ratio:.1%}\n",
    "        \n",
    "        Provide comprehensive credit risk assessment with specific recommendations.\n",
    "        \"\"\"\n",
    "        \n",
    "        assessment_text = get_completion(system_prompt, application_prompt)\n",
    "        \n",
    "        # Extract structured information (simplified for demo)\n",
    "        recommendation = self._extract_recommendation(assessment_text)\n",
    "        risk_score = self._extract_risk_score(assessment_text)\n",
    "        interest_rate = self._calculate_interest_rate(application, risk_score)\n",
    "        confidence = self._extract_confidence(assessment_text)\n",
    "        \n",
    "        return CreditAssessment(\n",
    "            applicant_name=application.applicant_name,\n",
    "            assessment_text=assessment_text,\n",
    "            recommendation=recommendation,\n",
    "            risk_score=risk_score,\n",
    "            interest_rate=interest_rate,\n",
    "            key_factors=self._extract_factors(assessment_text),\n",
    "            risk_mitigation=self._extract_mitigation(assessment_text),\n",
    "            confidence_level=confidence,\n",
    "            timestamp=datetime.now().isoformat()\n",
    "        )\n",
    "    \n",
    "    def _extract_recommendation(self, text: str) -> str:\n",
    "        \"\"\"Extract recommendation from assessment text\"\"\"\n",
    "        text_lower = text.lower()\n",
    "        if 'approve' in text_lower and 'conditional' not in text_lower:\n",
    "            return \"Approve\"\n",
    "        elif 'conditional' in text_lower or 'conditions' in text_lower:\n",
    "            return \"Conditional\"\n",
    "        elif 'decline' in text_lower or 'reject' in text_lower:\n",
    "            return \"Decline\"\n",
    "        else:\n",
    "            return \"Conditional\"  # Default to conditional\n",
    "    \n",
    "    def _extract_risk_score(self, text: str) -> float:\n",
    "        \"\"\"Extract risk score from assessment (simplified)\"\"\"\n",
    "        # Look for numerical risk indicators\n",
    "        if 'low risk' in text.lower():\n",
    "            return 3.5\n",
    "        elif 'medium risk' in text.lower() or 'moderate' in text.lower():\n",
    "            return 6.0\n",
    "        elif 'high risk' in text.lower():\n",
    "            return 8.5\n",
    "        else:\n",
    "            return 5.5  # Default medium-low risk\n",
    "    \n",
    "    def _calculate_interest_rate(self, application: CreditApplication, risk_score: float) -> float:\n",
    "        \"\"\"Calculate interest rate based on risk profile\"\"\"\n",
    "        base_rate = 4.5\n",
    "        credit_adjustment = (850 - application.credit_score) / 100 * 0.5\n",
    "        risk_adjustment = (risk_score - 1) / 9 * 3.0\n",
    "        return round(base_rate + credit_adjustment + risk_adjustment, 2)\n",
    "    \n",
    "    def _extract_confidence(self, text: str) -> float:\n",
    "        \"\"\"Extract confidence level from text\"\"\"\n",
    "        # Look for confidence indicators\n",
    "        confidence_patterns = re.findall(r'confidence[:\\s]*([0-9]+(?:\\.[0-9]+)?)', text.lower())\n",
    "        if confidence_patterns:\n",
    "            return min(float(confidence_patterns[0]), 10.0)\n",
    "        else:\n",
    "            return 7.5  # Default confidence\n",
    "    \n",
    "    def _extract_factors(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract key factors from assessment text\"\"\"\n",
    "        factors = []\n",
    "        if 'income' in text.lower():\n",
    "            factors.append(\"Income stability\")\n",
    "        if 'credit score' in text.lower() or 'credit history' in text.lower():\n",
    "            factors.append(\"Credit history\")\n",
    "        if 'employment' in text.lower():\n",
    "            factors.append(\"Employment history\")\n",
    "        if 'debt' in text.lower():\n",
    "            factors.append(\"Debt levels\")\n",
    "        return factors\n",
    "    \n",
    "    def _extract_mitigation(self, text: str) -> List[str]:\n",
    "        \"\"\"Extract risk mitigation factors\"\"\"\n",
    "        mitigation = []\n",
    "        if 'collateral' in text.lower():\n",
    "            mitigation.append(\"Collateral backing\")\n",
    "        if 'stable' in text.lower() and 'employment' in text.lower():\n",
    "            mitigation.append(\"Stable employment\")\n",
    "        if 'good' in text.lower() and 'credit' in text.lower():\n",
    "            mitigation.append(\"Strong credit profile\")\n",
    "        return mitigation\n",
    "    \n",
    "    def integrate_feedback(self, feedback: EvaluationFeedback):\n",
    "        \"\"\"Integrate evaluator feedback for improvement\"\"\"\n",
    "        self.feedback_history.append(feedback)\n",
    "        \n",
    "        # Build improvement context from feedback\n",
    "        if feedback.improvement_suggestions:\n",
    "            suggestions_text = \"\\n\".join([f\"- {s}\" for s in feedback.improvement_suggestions])\n",
    "            \n",
    "            self.improvement_context = f\"\"\"\n",
    "            IMPORTANT: Based on previous analysis feedback, ensure you address these areas:\n",
    "            {suggestions_text}\n",
    "            \n",
    "            Focus particularly on providing detailed analysis in areas that were previously identified as weak.\n",
    "            \"\"\"\n",
    "        \n",
    "        print(f\"🔄 Feedback integrated - {len(feedback.improvement_suggestions)} improvement areas noted\")\n",
    "\n",
    "# Initialize the analyst\n",
    "analyst = CreditAnalyst()\n",
    "print(\"✅ Advanced credit analyst with feedback integration initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8a98f7",
   "metadata": {},
   "source": [
    "## Evaluator LLM: Assessment Quality Control\n",
    "\n",
    "Now let's create the evaluator LLM that provides feedback to improve analysis quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025026ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreditEvaluator:\n",
    "    \"\"\"Evaluator LLM for assessing analysis quality\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.evaluation_criteria = [\n",
    "            \"Risk Assessment Completeness\",\n",
    "            \"Financial Analysis Depth\", \n",
    "            \"Regulatory Compliance\",\n",
    "            \"Decision Justification\",\n",
    "            \"Risk Mitigation Coverage\",\n",
    "            \"Market Context Integration\",\n",
    "            \"Documentation Quality\",\n",
    "            \"Professional Standards\"\n",
    "        ]\n",
    "    \n",
    "    def evaluate_assessment(self, assessment: CreditAssessment, application: CreditApplication) -> EvaluationFeedback:\n",
    "        \"\"\"Evaluate credit assessment quality and provide feedback\"\"\"\n",
    "        \n",
    "        evaluator_prompt = f\"\"\"You are a senior credit risk manager evaluating the quality of credit assessments.\n",
    "        \n",
    "        EVALUATION CRITERIA (Rate each 1-10):\n",
    "        1. Risk Assessment Completeness - Are all major risk factors identified?\n",
    "        2. Financial Analysis Depth - Is the financial analysis thorough and accurate?\n",
    "        3. Regulatory Compliance - Does assessment meet banking standards?\n",
    "        4. Decision Justification - Is the recommendation well-reasoned?\n",
    "        5. Risk Mitigation Coverage - Are mitigation strategies identified?\n",
    "        6. Market Context Integration - Consider economic and industry factors?\n",
    "        7. Documentation Quality - Is analysis well-structured and clear?\n",
    "        8. Professional Standards - Meets institutional underwriting standards?\n",
    "        \n",
    "        ASSESSMENT TO EVALUATE:\n",
    "        {assessment.assessment_text}\n",
    "        \n",
    "        APPLICATION CONTEXT:\n",
    "        - Credit Score: {application.credit_score}\n",
    "        - Income: ${application.annual_income:,.2f}\n",
    "        - Loan Amount: ${application.loan_amount:,.2f}\n",
    "        - DTI Ratio: {application.debt_to_income_ratio:.1%}\n",
    "        \n",
    "        Provide structured feedback in this format:\n",
    "        \n",
    "        SCORES: [score1, score2, score3, score4, score5, score6, score7, score8]\n",
    "        OVERALL_SCORE: [average score]\n",
    "        STRENGTHS: [list key strengths]\n",
    "        WEAKNESSES: [list main weaknesses] \n",
    "        IMPROVEMENTS: [specific suggestions for improvement]\n",
    "        MISSING: [elements missing from analysis]\n",
    "        \"\"\"\n",
    "        \n",
    "        evaluation_text = get_completion(\n",
    "            \"You are an expert credit risk manager with 15+ years experience evaluating loan assessments.\",\n",
    "            evaluator_prompt,\n",
    "            temperature=0.2  # Lower temperature for consistent evaluation\n",
    "        )\n",
    "        \n",
    "        # Parse the structured feedback\n",
    "        return self._parse_feedback(evaluation_text)\n",
    "    \n",
    "    def _parse_feedback(self, evaluation_text: str) -> EvaluationFeedback:\n",
    "        \"\"\"Parse structured feedback from evaluator response\"\"\"\n",
    "        \n",
    "        lines = evaluation_text.split('\\n')\n",
    "        scores = [7.0] * 8  # Default scores\n",
    "        overall_score = 7.0\n",
    "        strengths = []\n",
    "        weaknesses = []\n",
    "        improvements = []\n",
    "        missing = []\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            \n",
    "            if line.startswith('SCORES:'):\n",
    "                try:\n",
    "                    score_text = line.replace('SCORES:', '').strip('[]')\n",
    "                    scores = [float(x.strip()) for x in score_text.split(',')]\n",
    "                except:\n",
    "                    scores = [7.0] * 8\n",
    "            \n",
    "            elif line.startswith('OVERALL_SCORE:'):\n",
    "                try:\n",
    "                    overall_score = float(line.replace('OVERALL_SCORE:', '').strip())\n",
    "                except:\n",
    "                    overall_score = sum(scores) / len(scores)\n",
    "            \n",
    "            elif line.startswith('STRENGTHS:'):\n",
    "                strengths_text = line.replace('STRENGTHS:', '').strip('[]')\n",
    "                if strengths_text:\n",
    "                    strengths = [s.strip() for s in strengths_text.split(',')]\n",
    "            \n",
    "            elif line.startswith('WEAKNESSES:'):\n",
    "                weaknesses_text = line.replace('WEAKNESSES:', '').strip('[]')\n",
    "                if weaknesses_text:\n",
    "                    weaknesses = [w.strip() for w in weaknesses_text.split(',')]\n",
    "            \n",
    "            elif line.startswith('IMPROVEMENTS:'):\n",
    "                improvements_text = line.replace('IMPROVEMENTS:', '').strip('[]')\n",
    "                if improvements_text:\n",
    "                    improvements = [i.strip() for i in improvements_text.split(',')]\n",
    "            \n",
    "            elif line.startswith('MISSING:'):\n",
    "                missing_text = line.replace('MISSING:', '').strip('[]')\n",
    "                if missing_text:\n",
    "                    missing = [m.strip() for m in missing_text.split(',')]\n",
    "        \n",
    "        # Create criteria scores dictionary\n",
    "        criteria_scores = {}\n",
    "        for i, criterion in enumerate(self.evaluation_criteria):\n",
    "            if i < len(scores):\n",
    "                criteria_scores[criterion] = scores[i]\n",
    "        \n",
    "        return EvaluationFeedback(\n",
    "            overall_score=overall_score,\n",
    "            strengths=strengths,\n",
    "            weaknesses=weaknesses,\n",
    "            improvement_suggestions=improvements,\n",
    "            missing_analysis=missing,\n",
    "            criteria_scores=criteria_scores\n",
    "        )\n",
    "\n",
    "# Initialize the evaluator\n",
    "evaluator = CreditEvaluator()\n",
    "print(\"✅ Credit assessment evaluator initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671f2406",
   "metadata": {},
   "source": [
    "## Feedback Loop Implementation\n",
    "\n",
    "Now let's implement the complete feedback loop with iterative improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f63f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedbackLoopSystem:\n",
    "    \"\"\"Complete LLM feedback loop system for credit assessment\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.analyst = CreditAnalyst()\n",
    "        self.evaluator = CreditEvaluator()\n",
    "        self.iteration_history = []\n",
    "    \n",
    "    def run_feedback_loop(self, application: CreditApplication, max_iterations=3):\n",
    "        \"\"\"Run complete feedback loop with iterative improvement\"\"\"\n",
    "        \n",
    "        print(\"🚀 STARTING LLM FEEDBACK LOOP SYSTEM\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        for iteration in range(1, max_iterations + 1):\n",
    "            print(f\"\\n📊 ITERATION {iteration}\")\n",
    "            print(\"-\" * 40)\n",
    "            \n",
    "            # Step 1: Generate assessment\n",
    "            print(\"🤖 Analyst LLM: Generating credit assessment...\")\n",
    "            assessment = self.analyst.generate_assessment(application, iteration)\n",
    "            \n",
    "            # Step 2: Evaluate assessment quality\n",
    "            print(\"🔍 Evaluator LLM: Evaluating assessment quality...\")\n",
    "            feedback = self.evaluator.evaluate_assessment(assessment, application)\n",
    "            \n",
    "            # Step 3: Display results\n",
    "            self._display_iteration_results(iteration, assessment, feedback)\n",
    "            \n",
    "            # Step 4: Store iteration\n",
    "            self.iteration_history.append({\n",
    "                'iteration': iteration,\n",
    "                'assessment': assessment,\n",
    "                'feedback': feedback\n",
    "            })\n",
    "            \n",
    "            # Step 5: Integrate feedback for next iteration\n",
    "            if iteration < max_iterations:\n",
    "                self.analyst.integrate_feedback(feedback)\n",
    "                \n",
    "                # Check if we should continue (early stopping if quality is high)\n",
    "                if feedback.overall_score >= 8.5:\n",
    "                    print(f\"\\n🎯 EARLY STOPPING: High quality achieved (Score: {feedback.overall_score:.1f}/10)\")\n",
    "                    break\n",
    "            \n",
    "        return self.iteration_history\n",
    "    \n",
    "    def _display_iteration_results(self, iteration: int, assessment: CreditAssessment, feedback: EvaluationFeedback):\n",
    "        \"\"\"Display results for each iteration\"\"\"\n",
    "        \n",
    "        print(f\"\\n📋 Assessment Summary:\")\n",
    "        print(f\"   Recommendation: {assessment.recommendation}\")\n",
    "        print(f\"   Risk Score: {assessment.risk_score:.1f}/10\")\n",
    "        print(f\"   Interest Rate: {assessment.interest_rate}%\")\n",
    "        print(f\"   Confidence: {assessment.confidence_level:.1f}/10\")\n",
    "        \n",
    "        print(f\"\\n📊 Evaluation Results:\")\n",
    "        print(f\"   Overall Score: {feedback.overall_score:.1f}/10\")\n",
    "        print(f\"   Strengths: {len(feedback.strengths)} identified\")\n",
    "        print(f\"   Areas for Improvement: {len(feedback.improvement_suggestions)} identified\")\n",
    "        \n",
    "        if feedback.improvement_suggestions:\n",
    "            print(f\"\\n🔧 Key Improvement Areas:\")\n",
    "            for suggestion in feedback.improvement_suggestions[:3]:  # Show top 3\n",
    "                print(f\"   • {suggestion}\")\n",
    "    \n",
    "    def analyze_improvement(self):\n",
    "        \"\"\"Analyze improvement across iterations\"\"\"\n",
    "        \n",
    "        if len(self.iteration_history) < 2:\n",
    "            print(\"Need at least 2 iterations to analyze improvement\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n📈 IMPROVEMENT ANALYSIS\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        scores = [iter_data['feedback'].overall_score for iter_data in self.iteration_history]\n",
    "        \n",
    "        print(f\"📊 Quality Scores by Iteration:\")\n",
    "        for i, score in enumerate(scores, 1):\n",
    "            improvement = \"\"\n",
    "            if i > 1:\n",
    "                change = score - scores[i-2]\n",
    "                if change > 0:\n",
    "                    improvement = f\" (+{change:.1f})\"\n",
    "                elif change < 0:\n",
    "                    improvement = f\" ({change:.1f})\"\n",
    "                else:\n",
    "                    improvement = \" (no change)\"\n",
    "            \n",
    "            print(f\"   Iteration {i}: {score:.1f}/10{improvement}\")\n",
    "        \n",
    "        total_improvement = scores[-1] - scores[0] if len(scores) > 1 else 0\n",
    "        print(f\"\\n🎯 Total Improvement: {total_improvement:+.1f} points\")\n",
    "        \n",
    "        if total_improvement > 0:\n",
    "            print(\"✅ System successfully improved through feedback loops!\")\n",
    "        elif total_improvement == 0:\n",
    "            print(\"➡️ System maintained consistent quality\")\n",
    "        else:\n",
    "            print(\"⚠️ Quality decreased - may need feedback refinement\")\n",
    "\n",
    "# Initialize and run the complete system\n",
    "feedback_system = FeedbackLoopSystem()\n",
    "print(\"✅ Complete LLM feedback loop system initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7390ff0c",
   "metadata": {},
   "source": [
    "## Live Demonstration: Feedback Loop in Action\n",
    "\n",
    "Let's see the complete feedback loop system in action with iterative improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfa2da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the complete feedback loop demonstration\n",
    "print(\"🎯 RUNNING COMPLETE FEEDBACK LOOP DEMONSTRATION\")\n",
    "iteration_results = feedback_system.run_feedback_loop(sample_application, max_iterations=3)\n",
    "\n",
    "# Analyze the improvement\n",
    "feedback_system.analyze_improvement()\n",
    "\n",
    "# Show detailed comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📊 DETAILED BEFORE/AFTER COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len(iteration_results) >= 2:\n",
    "    first_iteration = iteration_results[0]\n",
    "    last_iteration = iteration_results[-1]\n",
    "    \n",
    "    print(f\"\\n🔴 ITERATION 1 (Before Feedback):\")\n",
    "    print(f\"   Quality Score: {first_iteration['feedback'].overall_score:.1f}/10\")\n",
    "    print(f\"   Recommendation: {first_iteration['assessment'].recommendation}\")\n",
    "    print(f\"   Risk Score: {first_iteration['assessment'].risk_score:.1f}/10\")\n",
    "    print(f\"   Interest Rate: {first_iteration['assessment'].interest_rate}%\")\n",
    "    print(f\"   Confidence: {first_iteration['assessment'].confidence_level:.1f}/10\")\n",
    "    \n",
    "    print(f\"\\n🟢 ITERATION {len(iteration_results)} (After Feedback):\")\n",
    "    print(f\"   Quality Score: {last_iteration['feedback'].overall_score:.1f}/10\")\n",
    "    print(f\"   Recommendation: {last_iteration['assessment'].recommendation}\")\n",
    "    print(f\"   Risk Score: {last_iteration['assessment'].risk_score:.1f}/10\") \n",
    "    print(f\"   Interest Rate: {last_iteration['assessment'].interest_rate}%\")\n",
    "    print(f\"   Confidence: {last_iteration['assessment'].confidence_level:.1f}/10\")\n",
    "    \n",
    "    quality_change = last_iteration['feedback'].overall_score - first_iteration['feedback'].overall_score\n",
    "    print(f\"\\n📈 Quality Improvement: {quality_change:+.1f} points\")\n",
    "\n",
    "print(f\"\\n💡 FEEDBACK LOOP BENEFITS:\")\n",
    "print(f\"✅ Systematic quality improvement through AI-to-AI feedback\")\n",
    "print(f\"✅ Consistent evaluation criteria ensuring objective assessment\")\n",
    "print(f\"✅ Iterative refinement leading to higher quality outputs\")\n",
    "print(f\"✅ Self-learning system that improves over time\")\n",
    "print(f\"✅ Reduced need for human intervention in quality control\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd439ff5",
   "metadata": {},
   "source": [
    "## Comparison: Single-Pass vs. Feedback Loop System\n",
    "\n",
    "Let's compare the quality and reliability of our feedback loop approach versus single-pass analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7593c249",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔄 COMPREHENSIVE SYSTEM COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n📊 SINGLE-PASS ANALYSIS LIMITATIONS:\")\n",
    "print(\"❌ No quality verification or improvement mechanism\")\n",
    "print(\"❌ Inconsistent analysis depth and structure\")\n",
    "print(\"❌ Potential gaps in risk assessment coverage\")\n",
    "print(\"❌ No learning or adaptation capability\")\n",
    "print(\"❌ Human intervention required for quality control\")\n",
    "\n",
    "print(\"\\n📊 FEEDBACK LOOP SYSTEM ADVANTAGES:\")\n",
    "print(\"✅ Systematic quality improvement through iterative refinement\")\n",
    "print(\"✅ Objective evaluation criteria ensuring consistent standards\")\n",
    "print(\"✅ Self-learning capability reduces need for human oversight\")\n",
    "print(\"✅ Continuous improvement leads to higher accuracy over time\")\n",
    "print(\"✅ Structured feedback integration for targeted improvements\")\n",
    "print(\"✅ Scalable system that gets better with more iterations\")\n",
    "\n",
    "if iteration_results:\n",
    "    final_iteration = iteration_results[-1]\n",
    "    \n",
    "    print(f\"\\n🎯 FEEDBACK SYSTEM PERFORMANCE METRICS:\")\n",
    "    print(f\"✅ Final Quality Score: {final_iteration['feedback'].overall_score:.1f}/10\")\n",
    "    print(f\"✅ Total Iterations: {len(iteration_results)}\")\n",
    "    print(f\"✅ Improvement Areas Identified: {len(final_iteration['feedback'].improvement_suggestions)}\")\n",
    "    print(f\"✅ Assessment Confidence: {final_iteration['assessment'].confidence_level:.1f}/10\")\n",
    "    \n",
    "    # Check if system achieved high quality\n",
    "    if final_iteration['feedback'].overall_score >= 8.0:\n",
    "        print(f\"✅ ACHIEVEMENT: High-quality assessment achieved!\")\n",
    "    elif final_iteration['feedback'].overall_score >= 7.0:\n",
    "        print(f\"✅ GOOD: Above-average quality assessment\")\n",
    "    else:\n",
    "        print(f\"⚠️ OPPORTUNITY: System shows improvement potential\")\n",
    "\n",
    "print(f\"\\n💼 BUSINESS IMPACT OF FEEDBACK LOOPS:\")\n",
    "print(f\"• Reduced manual review requirements\")\n",
    "print(f\"• Improved consistency in credit decisions\")  \n",
    "print(f\"• Enhanced risk assessment accuracy\")\n",
    "print(f\"• Scalable quality improvement\")\n",
    "print(f\"• Reduced operational costs over time\")\n",
    "print(f\"• Better regulatory compliance through systematic improvement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1c1314",
   "metadata": {},
   "source": [
    "## Key Observations and Best Practices\n",
    "\n",
    "### What We Learned:\n",
    "\n",
    "1. **LLM-to-LLM Feedback Works**: AI systems can effectively evaluate and improve each other's outputs\n",
    "\n",
    "2. **Iterative Improvement**: Multiple rounds of analysis → evaluation → refinement lead to measurably better results\n",
    "\n",
    "3. **Structured Evaluation**: Clear criteria and systematic feedback are essential for effective improvement\n",
    "\n",
    "4. **Quality Convergence**: Systems tend to improve rapidly in early iterations, then stabilize at higher quality levels\n",
    "\n",
    "5. **Self-Learning Systems**: Properly designed feedback loops create AI systems that improve autonomously\n",
    "\n",
    "### LLM Feedback Loop Best Practices for Financial Services:\n",
    "\n",
    "- **Clear Evaluation Criteria**: Define specific, measurable quality standards for assessment\n",
    "- **Structured Feedback**: Use consistent formats for feedback integration and improvement\n",
    "- **Iterative Limits**: Set maximum iterations to balance quality improvement with efficiency\n",
    "- **Quality Thresholds**: Implement early stopping when acceptable quality levels are reached\n",
    "- **Feedback Integration**: Design systems that can effectively incorporate evaluation insights\n",
    "\n",
    "### Real-World Applications:\n",
    "\n",
    "- **Credit Underwriting**: Self-improving loan assessment systems with continuous quality enhancement\n",
    "- **Investment Analysis**: Stock research systems that improve through peer AI evaluation\n",
    "- **Fraud Detection**: Transaction monitoring systems that refine detection accuracy over time  \n",
    "- **Compliance Monitoring**: Regulatory analysis systems with built-in quality control loops"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
