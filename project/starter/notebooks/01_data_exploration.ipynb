{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77ab9e49",
   "metadata": {},
   "source": [
    "# ğŸ“Š Data Exploration - SAR Processing System\n",
    "\n",
    "Welcome to Phase 1 of the Financial Services Agentic AI Project!\n",
    "\n",
    "In this notebook, you'll explore the financial data that forms the foundation of our SAR (Suspicious Activity Report) processing system. Understanding this data is crucial for designing effective Pydantic schemas and building your AI agents.\n",
    "\n",
    "## ğŸ¯ Learning Objectives\n",
    "- Understand the structure of customer, account, and transaction data\n",
    "- Identify relationships between different data entities\n",
    "- Recognize patterns that might indicate suspicious activity\n",
    "- Prepare for designing Pydantic schemas in `foundation_sar.py`\n",
    "\n",
    "## ğŸ“‹ Business Context\n",
    "Financial institutions are required by law to monitor customer transactions and report suspicious activities to authorities. This process involves:\n",
    "- **Customer Due Diligence**: Understanding who your customers are\n",
    "- **Transaction Monitoring**: Watching for unusual patterns\n",
    "- **Risk Assessment**: Evaluating the likelihood of financial crimes\n",
    "- **Regulatory Reporting**: Filing SARs when required"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1894634",
   "metadata": {},
   "source": [
    "## ğŸš€ Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4916bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "\n",
    "print(\"ğŸ“š Libraries loaded successfully!\")\n",
    "print(\"ğŸ¯ Ready to explore financial data for SAR processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90555223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the three main data files\n",
    "customers_df = pd.read_csv('../data/customers.csv')\n",
    "accounts_df = pd.read_csv('../data/accounts.csv')\n",
    "transactions_df = pd.read_csv('../data/transactions.csv')\n",
    "\n",
    "print(\"ğŸ“Š Data loaded successfully!\")\n",
    "print(f\"ğŸ‘¥ Customers: {len(customers_df):,} records\")\n",
    "print(f\"ğŸ¦ Accounts: {len(accounts_df):,} records\")\n",
    "print(f\"ğŸ’³ Transactions: {len(transactions_df):,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a81931",
   "metadata": {},
   "source": [
    "## ğŸ‘¥ Customer Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5570208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore customer data structure\n",
    "print(\"ğŸ“‹ Customer Data Overview\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {customers_df.shape}\")\n",
    "print(f\"Columns: {list(customers_df.columns)}\")\n",
    "print(\"\\nğŸ“Š First few records:\")\n",
    "customers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3ebcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze customer data types and missing values\n",
    "print(\"ğŸ” Customer Data Quality Analysis\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nğŸ“Š Data Types:\")\n",
    "print(customers_df.dtypes)\n",
    "print(\"\\nâ“ Missing Values:\")\n",
    "print(customers_df.isnull().sum())\n",
    "print(\"\\nğŸ“ˆ Basic Statistics:\")\n",
    "customers_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2474eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze risk ratings distribution\n",
    "print(\"âš ï¸ Customer Risk Rating Analysis\")\n",
    "print(\"=\" * 50)\n",
    "risk_counts = customers_df['risk_rating'].value_counts()\n",
    "print(risk_counts)\n",
    "\n",
    "# Visualize risk distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "risk_counts.plot(kind='bar', color=['green', 'orange', 'red'])\n",
    "plt.title('Customer Risk Rating Distribution')\n",
    "plt.ylabel('Number of Customers')\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.pie(risk_counts.values, labels=risk_counts.index, autopct='%1.1f%%', \n",
    "        colors=['green', 'orange', 'red'])\n",
    "plt.title('Risk Rating Percentage')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nğŸ’¡ Key Insights:\")\n",
    "print(f\"â€¢ {risk_counts['High']} customers ({risk_counts['High']/len(customers_df)*100:.1f}%) are High Risk\")\n",
    "print(f\"â€¢ These high-risk customers require enhanced monitoring\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52de5b18",
   "metadata": {},
   "source": [
    "### ğŸ“ TODO: Design CustomerData Schema\n",
    "\n",
    "Based on your exploration above, you'll need to create a Pydantic schema in `foundation_sar.py` that includes:\n",
    "\n",
    "```python\n",
    "class CustomerData(BaseModel):\n",
    "    customer_id: str = Field(..., description=\"Unique customer identifier\")\n",
    "    # TODO: Add all other fields with appropriate types\n",
    "    # Consider: validation rules, optional fields, field descriptions\n",
    "```\n",
    "\n",
    "**Questions to consider:**\n",
    "- Which fields are required vs optional?\n",
    "- What validation rules should you add (e.g., date formats, risk rating values)?\n",
    "- How will you handle the SSN field for privacy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941d818c",
   "metadata": {},
   "source": [
    "## ğŸ¦ Account Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf04e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore account data structure\n",
    "print(\"ğŸ“‹ Account Data Overview\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {accounts_df.shape}\")\n",
    "print(f\"Columns: {list(accounts_df.columns)}\")\n",
    "print(\"\\nğŸ“Š First few records:\")\n",
    "accounts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ca6deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze account types and balances\n",
    "print(\"ğŸ’° Account Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Account types\n",
    "print(\"\\nğŸ¦ Account Types:\")\n",
    "account_types = accounts_df['account_type'].value_counts()\n",
    "print(account_types)\n",
    "\n",
    "# Balance analysis\n",
    "print(\"\\nğŸ’µ Balance Statistics:\")\n",
    "print(accounts_df[['current_balance', 'average_monthly_balance']].describe())\n",
    "\n",
    "# Visualize balance distributions\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "account_types.plot(kind='bar')\n",
    "plt.title('Account Types Distribution')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(accounts_df['current_balance'], bins=50, alpha=0.7, color='blue')\n",
    "plt.title('Current Balance Distribution')\n",
    "plt.xlabel('Balance ($)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(accounts_df['current_balance'], accounts_df['average_monthly_balance'], alpha=0.6)\n",
    "plt.title('Current vs Average Monthly Balance')\n",
    "plt.xlabel('Current Balance ($)')\n",
    "plt.ylabel('Average Monthly Balance ($)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9754c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze customer-account relationships\n",
    "print(\"ğŸ”— Customer-Account Relationships\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# How many accounts per customer?\n",
    "accounts_per_customer = accounts_df.groupby('customer_id').size()\n",
    "print(\"\\nğŸ“Š Accounts per Customer:\")\n",
    "print(accounts_per_customer.value_counts().sort_index())\n",
    "\n",
    "# Customers with multiple accounts\n",
    "multi_account_customers = accounts_per_customer[accounts_per_customer > 1]\n",
    "print(f\"\\nğŸ‘¥ Customers with multiple accounts: {len(multi_account_customers)}\")\n",
    "print(f\"ğŸ“ˆ Max accounts per customer: {accounts_per_customer.max()}\")\n",
    "\n",
    "# Visualize accounts per customer\n",
    "plt.figure(figsize=(10, 6))\n",
    "accounts_per_customer.value_counts().sort_index().plot(kind='bar')\n",
    "plt.title('Distribution of Accounts per Customer')\n",
    "plt.xlabel('Number of Accounts')\n",
    "plt.ylabel('Number of Customers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cee698d",
   "metadata": {},
   "source": [
    "### ğŸ“ TODO: Design AccountData Schema\n",
    "\n",
    "Key considerations for your AccountData schema:\n",
    "- How will you link accounts to customers?\n",
    "- What validation is needed for balance fields?\n",
    "- How will you handle account status values?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8b932d",
   "metadata": {},
   "source": [
    "## ğŸ’³ Transaction Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d61c828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore transaction data structure\n",
    "print(\"ğŸ“‹ Transaction Data Overview\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {transactions_df.shape}\")\n",
    "print(f\"Columns: {list(transactions_df.columns)}\")\n",
    "print(\"\\nğŸ“Š First few records:\")\n",
    "transactions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21823926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert transaction_date to datetime for analysis\n",
    "transactions_df['transaction_date'] = pd.to_datetime(transactions_df['transaction_date'])\n",
    "\n",
    "print(\"ğŸ’° Transaction Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Transaction types\n",
    "print(\"\\nğŸ“Š Transaction Types:\")\n",
    "txn_types = transactions_df['transaction_type'].value_counts()\n",
    "print(txn_types)\n",
    "\n",
    "# Transaction methods\n",
    "print(\"\\nğŸ’³ Transaction Methods:\")\n",
    "txn_methods = transactions_df['method'].value_counts()\n",
    "print(txn_methods)\n",
    "\n",
    "# Amount statistics\n",
    "print(\"\\nğŸ’µ Transaction Amount Statistics:\")\n",
    "print(transactions_df['amount'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35841a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze transaction patterns for suspicious activity indicators\n",
    "print(\"ğŸš¨ Suspicious Activity Pattern Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Large transactions (potential money laundering)\n",
    "large_transactions = transactions_df[transactions_df['amount'] >= 100000]\n",
    "print(f\"\\nğŸ’° Large transactions (â‰¥$100k): {len(large_transactions)}\")\n",
    "\n",
    "# Transactions just under $10k (potential structuring)\n",
    "structuring_range = transactions_df[\n",
    "    (transactions_df['amount'] >= 9000) & \n",
    "    (transactions_df['amount'] < 10000)\n",
    "]\n",
    "print(f\"ğŸ”„ Potential structuring ($9k-$10k): {len(structuring_range)}\")\n",
    "\n",
    "# High-frequency customers (many transactions)\n",
    "txn_per_account = transactions_df.groupby('account_id').size()\n",
    "high_frequency_accounts = txn_per_account[txn_per_account >= 50]\n",
    "print(f\"ğŸ“ˆ High-frequency accounts (â‰¥50 txns): {len(high_frequency_accounts)}\")\n",
    "\n",
    "# Wire transfers (higher risk method)\n",
    "wire_transfers = transactions_df[transactions_df['method'] == 'Wire']\n",
    "print(f\"ğŸŒ Wire transfers: {len(wire_transfers)}\")\n",
    "\n",
    "print(f\"\\nâš ï¸ Potential Suspicious Indicators:\")\n",
    "print(f\"â€¢ {len(large_transactions)} large transactions requiring enhanced scrutiny\")\n",
    "print(f\"â€¢ {len(structuring_range)} transactions in structuring range\")\n",
    "print(f\"â€¢ {len(high_frequency_accounts)} accounts with high transaction frequency\")\n",
    "print(f\"â€¢ {len(wire_transfers)} wire transfers (higher risk method)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1d1f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize transaction patterns\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Transaction amounts distribution\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.hist(transactions_df['amount'], bins=50, alpha=0.7)\n",
    "plt.title('Transaction Amount Distribution')\n",
    "plt.xlabel('Amount ($)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.yscale('log')  # Log scale due to wide range\n",
    "\n",
    "# Transaction types\n",
    "plt.subplot(2, 3, 2)\n",
    "txn_types.plot(kind='bar')\n",
    "plt.title('Transaction Types')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Transaction methods\n",
    "plt.subplot(2, 3, 3)\n",
    "txn_methods.plot(kind='bar')\n",
    "plt.title('Transaction Methods')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Daily transaction volume\n",
    "plt.subplot(2, 3, 4)\n",
    "daily_volume = transactions_df.groupby(transactions_df['transaction_date'].dt.date)['amount'].sum()\n",
    "daily_volume.plot()\n",
    "plt.title('Daily Transaction Volume')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Transaction count per account\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.hist(txn_per_account, bins=30, alpha=0.7)\n",
    "plt.title('Transactions per Account')\n",
    "plt.xlabel('Number of Transactions')\n",
    "plt.ylabel('Number of Accounts')\n",
    "\n",
    "# Structuring analysis\n",
    "plt.subplot(2, 3, 6)\n",
    "amount_ranges = pd.cut(transactions_df['amount'], \n",
    "                      bins=[0, 5000, 9000, 10000, 50000, float('inf')],\n",
    "                      labels=['<$5k', '$5k-$9k', '$9k-$10k', '$10k-$50k', '>$50k'])\n",
    "amount_ranges.value_counts().plot(kind='bar')\n",
    "plt.title('Transaction Amount Ranges (Structuring Analysis)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f91ba45",
   "metadata": {},
   "source": [
    "## ğŸ”— Data Relationships Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d30c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the complete data relationship chain\n",
    "print(\"ğŸ”— Complete Data Relationship Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Join all datasets to understand relationships\n",
    "# First join accounts with customers\n",
    "customer_accounts = accounts_df.merge(customers_df, on='customer_id', how='left')\n",
    "\n",
    "# Then join with transactions\n",
    "full_data = transactions_df.merge(customer_accounts, on='account_id', how='left')\n",
    "\n",
    "print(f\"\\nğŸ“Š Combined dataset shape: {full_data.shape}\")\n",
    "print(f\"âœ… Successful joins: {len(full_data[full_data['customer_id'].notna()])} / {len(full_data)}\")\n",
    "\n",
    "# Check for any orphaned records\n",
    "orphaned_transactions = full_data[full_data['customer_id'].isna()]\n",
    "if len(orphaned_transactions) > 0:\n",
    "    print(f\"âš ï¸ Found {len(orphaned_transactions)} orphaned transactions (no matching account/customer)\")\n",
    "else:\n",
    "    print(\"âœ… All transactions have valid account and customer relationships\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff55721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze high-risk customer activity\n",
    "print(\"âš ï¸ High-Risk Customer Activity Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Filter for high-risk customers\n",
    "high_risk_data = full_data[full_data['risk_rating'] == 'High']\n",
    "\n",
    "print(f\"\\nğŸ“Š High-risk customer transactions: {len(high_risk_data)}\")\n",
    "print(f\"ğŸ’° Total high-risk transaction volume: ${high_risk_data['amount'].sum():,.2f}\")\n",
    "print(f\"ğŸ“ˆ Average transaction amount: ${high_risk_data['amount'].mean():,.2f}\")\n",
    "\n",
    "# High-risk customers with large transactions\n",
    "high_risk_large = high_risk_data[high_risk_data['amount'] >= 50000]\n",
    "print(f\"\\nğŸš¨ High-risk customers with large transactions (â‰¥$50k): {len(high_risk_large)}\")\n",
    "\n",
    "if len(high_risk_large) > 0:\n",
    "    print(\"\\nğŸ” Sample high-risk large transactions:\")\n",
    "    print(high_risk_large[['name', 'amount', 'transaction_type', 'method', 'transaction_date']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a76de90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify potential cases for SAR processing\n",
    "print(\"ğŸ¯ Potential SAR Cases Identification\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Define criteria for suspicious cases\n",
    "def identify_suspicious_cases(df):\n",
    "    suspicious_criteria = {\n",
    "        'high_risk_customers': df['risk_rating'] == 'High',\n",
    "        'large_transactions': df['amount'] >= 100000,\n",
    "        'high_frequency': df.groupby('customer_id')['transaction_id'].transform('count') >= 50,\n",
    "        'wire_transfers': df['method'] == 'Wire'\n",
    "    }\n",
    "    \n",
    "    # Apply any of the criteria\n",
    "    suspicious_mask = (\n",
    "        suspicious_criteria['high_risk_customers'] |\n",
    "        suspicious_criteria['large_transactions'] |\n",
    "        suspicious_criteria['high_frequency'] |\n",
    "        suspicious_criteria['wire_transfers']\n",
    "    )\n",
    "    \n",
    "    return df[suspicious_mask], suspicious_criteria\n",
    "\n",
    "suspicious_data, criteria = identify_suspicious_cases(full_data)\n",
    "\n",
    "print(f\"\\nğŸ“Š Suspicious transactions identified: {len(suspicious_data)}\")\n",
    "print(f\"ğŸ‘¥ Unique customers involved: {suspicious_data['customer_id'].nunique()}\")\n",
    "\n",
    "# Break down by criteria\n",
    "print(\"\\nğŸ” Breakdown by criteria:\")\n",
    "for criterion, mask in criteria.items():\n",
    "    count = full_data[mask]['customer_id'].nunique()\n",
    "    print(f\"â€¢ {criterion.replace('_', ' ').title()}: {count} customers\")\n",
    "\n",
    "# Top customers by transaction volume\n",
    "customer_volumes = suspicious_data.groupby(['customer_id', 'name'])['amount'].agg(['sum', 'count']).reset_index()\n",
    "customer_volumes = customer_volumes.sort_values('sum', ascending=False)\n",
    "\n",
    "print(\"\\nğŸ’° Top 5 customers by suspicious transaction volume:\")\n",
    "print(customer_volumes.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390b45f8",
   "metadata": {},
   "source": [
    "## ğŸ“ Key Insights and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a153b8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of key insights for schema design\n",
    "print(\"ğŸ” DATA EXPLORATION SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nğŸ“Š Dataset Overview:\")\n",
    "print(f\"â€¢ {len(customers_df)} customers ({customers_df['risk_rating'].value_counts()['High']} high-risk)\")\n",
    "print(f\"â€¢ {len(accounts_df)} accounts ({accounts_df['account_type'].nunique()} types)\")\n",
    "print(f\"â€¢ {len(transactions_df)} transactions (${transactions_df['amount'].sum():,.2f} total volume)\")\n",
    "\n",
    "print(\"\\nğŸš¨ Suspicious Activity Indicators:\")\n",
    "print(f\"â€¢ {len(large_transactions)} large transactions (â‰¥$100k)\")\n",
    "print(f\"â€¢ {len(structuring_range)} potential structuring transactions ($9k-$10k)\")\n",
    "print(f\"â€¢ {len(high_frequency_accounts)} high-frequency accounts (â‰¥50 transactions)\")\n",
    "print(f\"â€¢ {suspicious_data['customer_id'].nunique()} customers with suspicious patterns\")\n",
    "\n",
    "print(\"\\nğŸ—ï¸ Schema Design Requirements:\")\n",
    "print(\"â€¢ CustomerData: Handle optional fields, validate risk ratings\")\n",
    "print(\"â€¢ AccountData: Link to customers, validate balances\")\n",
    "print(\"â€¢ TransactionData: Validate amounts, handle date formats\")\n",
    "print(\"â€¢ CaseData: Combine all entities with metadata\")\n",
    "\n",
    "print(\"\\nğŸ¯ Next Steps:\")\n",
    "print(\"1. Implement Pydantic schemas in src/foundation_sar.py\")\n",
    "print(\"2. Create DataLoader to build unified case objects\")\n",
    "print(\"3. Add comprehensive data validation\")\n",
    "print(\"4. Test with the suspicious cases identified above\")\n",
    "\n",
    "print(\"\\nğŸš€ Ready to move to Phase 2: Agent Development!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7f51a0",
   "metadata": {},
   "source": [
    "## ğŸ“‹ TODO: Implementation Checklist\n",
    "\n",
    "Based on your data exploration, complete these tasks in `src/foundation_sar.py`:\n",
    "\n",
    "### âœ… Pydantic Schemas\n",
    "- [ ] `CustomerData` - Include all customer fields with proper validation\n",
    "- [ ] `AccountData` - Include account details with balance validation\n",
    "- [ ] `TransactionData` - Include transaction fields with amount/date validation\n",
    "- [ ] `CaseData` - Combine customer, accounts, and transactions\n",
    "- [ ] `RiskAnalystOutput` - Structure for risk analysis results\n",
    "- [ ] `ComplianceOfficerOutput` - Structure for compliance narratives\n",
    "\n",
    "### âœ… Utility Classes\n",
    "- [ ] `ExplainabilityLogger` - Audit trail logging system\n",
    "- [ ] `DataLoader` - Case object creation from CSV data\n",
    "\n",
    "### âœ… Testing\n",
    "- [ ] Test schemas with the actual data from this exploration\n",
    "- [ ] Validate that all suspicious cases can be processed\n",
    "- [ ] Ensure proper error handling for edge cases\n",
    "\n",
    "**ğŸ’¡ Pro Tip**: Use the insights from this exploration to guide your validation rules. For example, you now know that risk ratings are 'Low', 'Medium', or 'High', so you can use a Literal type for validation."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
